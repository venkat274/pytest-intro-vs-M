{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"Demo\").getOrCreate()\n",
    "\n",
    "# Read CSV File\n",
    "df = spark.read.csv(\"C:/Users/venka/Data/zipcodes.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('C:/Users/venka/Data/datacamp_ecommerce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(_c0='x', _c1='age', _c2='workclass', _c3='fnlwgt', _c4='education', _c5='educational-num', _c6='marital-status', _c7='occupation', _c8='relationship', _c9='race', _c10='gender', _c11='capital-gain', _c12='capital-loss', _c13='hours-per-week', _c14='native-country', _c15='income'), Row(_c0='1', _c1='25', _c2='Private', _c3='226802', _c4='11th', _c5='7', _c6='Never-married', _c7='Machine-op-inspct', _c8='Own-child', _c9='Black', _c10='Male', _c11='0', _c12='0', _c13='40', _c14='United-States', _c15='<=50K'), Row(_c0='2', _c1='38', _c2='Private', _c3='89814', _c4='HS-grad', _c5='9', _c6='Married-civ-spouse', _c7='Farming-fishing', _c8='Husband', _c9='White', _c10='Male', _c11='0', _c12='0', _c13='50', _c14='United-States', _c15='<=50K'), Row(_c0='3', _c1='28', _c2='Local-gov', _c3='336951', _c4='Assoc-acdm', _c5='12', _c6='Married-civ-spouse', _c7='Protective-serv', _c8='Husband', _c9='White', _c10='Male', _c11='0', _c12='0', _c13='40', _c14='United-States', _c15='>50K'), Row(_c0='4', _c1='44', _c2='Private', _c3='160323', _c4='Some-college', _c5='10', _c6='Married-civ-spouse', _c7='Machine-op-inspct', _c8='Husband', _c9='Black', _c10='Male', _c11='7688', _c12='0', _c13='40', _c14='United-States', _c15='>50K')]\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('C:/Users/venka/Data/adult_data.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
